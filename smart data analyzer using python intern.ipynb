{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kqZ8oV_pLhj",
        "outputId": "3956bdd1-9d2e-4732-a674-696342d5a19f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/smart_data_analyzer\n"
          ]
        }
      ],
      "source": [
        "!mkdir smart_data_analyzer\n",
        "%cd smart_data_analyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lsBPhuuqrWx",
        "outputId": "54b2e2dd-c54c-4e12-d7e5-6ed95a1b3ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: ./venv/bin/pip: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!./venv/bin/pip install package_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1574OZaqtHV",
        "outputId": "b190de18-43b4-4733-a83c-1692a272adbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: ./venv/bin/python: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!./venv/bin/python your_script.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3052f2a",
        "outputId": "e01719e8-1daf-474f-c909-9558915f363e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: ./venv/bin/pip: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!./venv/bin/pip install pandas numpy scikit-learn matplotlib joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBLbcN39r6AE",
        "outputId": "f063df01-b610-4beb-9497-e8d1dc9a7df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No input provided â€” creating synthetic dataset.\n",
            "Data shape: (800, 7)\n",
            "Saved sample rows to ./output/data_sample.csv\n",
            "\n",
            ">>> Quick EDA\n",
            "age                    int64\n",
            "income               float64\n",
            "gender                object\n",
            "city                  object\n",
            "visits_last_month      int64\n",
            "avg_spend            float64\n",
            "target_high_value      int64\n",
            "dtype: object\n",
            "Missing values:\n",
            " age                   0\n",
            "income               24\n",
            "gender                0\n",
            "city                  0\n",
            "visits_last_month     0\n",
            "avg_spend            24\n",
            "target_high_value     0\n",
            "dtype: int64\n",
            "Saved ./output/age_histogram.png\n",
            "Saved ./output/income_vs_avgspend.png\n",
            "Saved ./output/target_distribution.png\n",
            "Numeric cols: ['age', 'income', 'visits_last_month', 'avg_spend']\n",
            "Categorical cols: ['gender', 'city']\n",
            "Split sizes: (640, 6) (160, 6)\n",
            "Preprocessing completed. Shapes: (640, 10) (160, 10)\n",
            "RandomForest train acc: 1.0000, test acc: 1.0000\n",
            "Classification report (test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       123\n",
            "           1       1.00      1.00      1.00        37\n",
            "\n",
            "    accuracy                           1.00       160\n",
            "   macro avg       1.00      1.00      1.00       160\n",
            "weighted avg       1.00      1.00      1.00       160\n",
            "\n",
            "Saved feature importances to ./output/feature_importances.csv\n",
            "Selected feature shapes: (640, 5) (160, 5)\n",
            "Logistic Regression test accuracy: 0.93125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       123\n",
            "           1       0.91      0.78      0.84        37\n",
            "\n",
            "    accuracy                           0.93       160\n",
            "   macro avg       0.92      0.88      0.90       160\n",
            "weighted avg       0.93      0.93      0.93       160\n",
            "\n",
            "ROC AUC: 0.9712151175565811\n",
            "Saved ROC curve to ./output/roc_curve.png\n",
            "Saved processed features to ./output/processed_features.csv\n",
            "Saved artifacts to ./output\n",
            "Selected features after thresholding: ['age', 'income', 'visits_last_month', 'avg_spend', 'gender_Female']\n",
            "\n",
            "Done. See outputs in: ./output\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "smart_data_analyzer.py\n",
        "\n",
        "Usage:\n",
        "  - Default (creates synthetic data):\n",
        "      python smart_data_analyzer.py\n",
        "\n",
        "  - Run on your CSV:\n",
        "      python smart_data_analyzer.py --input path/to/your.csv --target target_column_name --outdir ./output\n",
        "\n",
        "Outputs (in outdir):\n",
        "  - sample or processed csv\n",
        "  - plots: age_histogram.png, income_vs_avgspend.png, target_distribution.png, roc_curve.png\n",
        "  - model artifacts: preprocessor.joblib, selector.joblib, model.joblib\n",
        "\"\"\"\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
        "import joblib\n",
        "\n",
        "def create_synthetic(n=800, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    age = rng.integers(18, 75, size=n)\n",
        "    income = (age * rng.normal(800, 120, size=n) / 10 + rng.normal(2000, 1000, size=n)).astype(int)\n",
        "    gender = rng.choice(['Male', 'Female'], size=n, p=[0.48, 0.52])\n",
        "    city = rng.choice(['CityA', 'CityB', 'CityC', 'CityD'], size=n, p=[0.4,0.3,0.2,0.1])\n",
        "    visits_last_month = rng.poisson(3, size=n)\n",
        "    avg_spend = np.round(np.abs(rng.normal(300, 120, size=n)), 2)\n",
        "    target = ((income > np.percentile(income, 60)).astype(int) & (visits_last_month >= 3)).astype(int)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'age': age,\n",
        "        'income': income.astype(float),\n",
        "        'gender': gender,\n",
        "        'city': city,\n",
        "        'visits_last_month': visits_last_month,\n",
        "        'avg_spend': avg_spend,\n",
        "        'target_high_value': target\n",
        "    })\n",
        "\n",
        "    # inject a few missing values for demo\n",
        "    for col in ['income', 'avg_spend']:\n",
        "        idx = rng.choice(df.index, size=int(0.03 * n), replace=False)\n",
        "        df.loc[idx, col] = np.nan\n",
        "    return df\n",
        "\n",
        "def save_plot_hist(series, path, title=\"Histogram\", xlabel=None):\n",
        "    plt.figure()\n",
        "    plt.hist(series.dropna(), bins=12)\n",
        "    plt.title(title)\n",
        "    if xlabel: plt.xlabel(xlabel)\n",
        "    plt.ylabel('Count')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "def save_plot_scatter(x, y, path, title=\"Scatter\", xlabel=None, ylabel=None):\n",
        "    plt.figure()\n",
        "    plt.scatter(x.fillna(x.median()), y.fillna(y.median()), alpha=0.6)\n",
        "    plt.title(title)\n",
        "    if xlabel: plt.xlabel(xlabel)\n",
        "    if ylabel: plt.ylabel(ylabel)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "def save_plot_pie(series, path, title=\"Distribution\"):\n",
        "    plt.figure()\n",
        "    vc = series.value_counts()\n",
        "    plt.pie(vc, labels=vc.index.astype(str), autopct='%1.1f%%')\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "def ensure_dir(d):\n",
        "    if not os.path.exists(d):\n",
        "        os.makedirs(d, exist_ok=True)\n",
        "\n",
        "def main(args):\n",
        "    outdir = args.outdir or \"./output\"\n",
        "    ensure_dir(outdir)\n",
        "\n",
        "    # 1) Load or create data\n",
        "    if args.input:\n",
        "        print(f\"Loading input CSV: {args.input}\")\n",
        "        df = pd.read_csv(args.input)\n",
        "        if args.target is None:\n",
        "            raise SystemExit(\"When providing --input, you must provide --target target_column_name\")\n",
        "        target_col = args.target\n",
        "    else:\n",
        "        print(\"No input provided â€” creating synthetic dataset.\")\n",
        "        df = create_synthetic()\n",
        "        target_col = 'target_high_value'\n",
        "\n",
        "    print(\"Data shape:\", df.shape)\n",
        "    sample_csv = os.path.join(outdir, \"data_sample.csv\")\n",
        "    df.head(100).to_csv(sample_csv, index=False)\n",
        "    print(\"Saved sample rows to\", sample_csv)\n",
        "\n",
        "    # Quick EDA: dtypes and missing values\n",
        "    print(\"\\n>>> Quick EDA\")\n",
        "    print(df.dtypes)\n",
        "    print(\"Missing values:\\n\", df.isnull().sum())\n",
        "\n",
        "    # Make some helpful plots if relevant columns exist\n",
        "    # heuristics: use 'age', 'income', 'avg_spend' if present\n",
        "    if 'age' in df.columns:\n",
        "        p = os.path.join(outdir, 'age_histogram.png')\n",
        "        save_plot_hist(df['age'], p, title=\"Age distribution\", xlabel=\"Age\")\n",
        "        print(\"Saved\", p)\n",
        "    if 'income' in df.columns and 'avg_spend' in df.columns:\n",
        "        p = os.path.join(outdir, 'income_vs_avgspend.png')\n",
        "        save_plot_scatter(df['income'], df['avg_spend'], p, title=\"Income vs Avg Spend\", xlabel=\"Income\", ylabel=\"Avg Spend\")\n",
        "        print(\"Saved\", p)\n",
        "\n",
        "    if target_col in df.columns:\n",
        "        p = os.path.join(outdir, 'target_distribution.png')\n",
        "        save_plot_pie(df[target_col], p, title=f\"{target_col} distribution\")\n",
        "        print(\"Saved\", p)\n",
        "    else:\n",
        "        print(f\"Warning: target column '{target_col}' not in dataset; skipping distribution plot.\")\n",
        "\n",
        "    # 2) Preprocessing - separate X,y\n",
        "    if target_col not in df.columns:\n",
        "        raise SystemExit(f\"Target column '{target_col}' not found in data.\")\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col]\n",
        "\n",
        "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    print(\"Numeric cols:\", numeric_cols)\n",
        "    print(\"Categorical cols:\", cat_cols)\n",
        "\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
        "    ])\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "        ('num', numeric_transformer, numeric_cols),\n",
        "        ('cat', categorical_transformer, cat_cols)\n",
        "    ])\n",
        "\n",
        "    # 3) Split and train baseline RandomForest (for importance)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
        "    print(\"Split sizes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "    X_train_prep = preprocessor.fit_transform(X_train)\n",
        "    X_test_prep = preprocessor.transform(X_test)\n",
        "    print(\"Preprocessing completed. Shapes:\", X_train_prep.shape, X_test_prep.shape)\n",
        "\n",
        "    rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "    rf.fit(X_train_prep, y_train)\n",
        "    train_acc = accuracy_score(y_train, rf.predict(X_train_prep))\n",
        "    test_acc = accuracy_score(y_test, rf.predict(X_test_prep))\n",
        "    print(f\"RandomForest train acc: {train_acc:.4f}, test acc: {test_acc:.4f}\")\n",
        "    print(\"Classification report (test):\")\n",
        "    print(classification_report(y_test, rf.predict(X_test_prep)))\n",
        "\n",
        "    # Map importances back to names\n",
        "    try:\n",
        "        ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
        "        ohe_features = list(ohe.get_feature_names_out(cat_cols))\n",
        "    except Exception:\n",
        "        ohe_features = []\n",
        "    feature_names = numeric_cols + ohe_features\n",
        "    importances = rf.feature_importances_\n",
        "    fi_df = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False)\n",
        "    fi_path = os.path.join(outdir, 'feature_importances.csv')\n",
        "    fi_df.to_csv(fi_path, index=False)\n",
        "    print(\"Saved feature importances to\", fi_path)\n",
        "\n",
        "    # 4) Select features and retrain lightweight model\n",
        "    selector = SelectFromModel(rf, threshold='median', prefit=True)\n",
        "    X_train_sel = selector.transform(X_train_prep)\n",
        "    X_test_sel = selector.transform(X_test_prep)\n",
        "    print(\"Selected feature shapes:\", X_train_sel.shape, X_test_sel.shape)\n",
        "\n",
        "    logreg = LogisticRegression(max_iter=1000)\n",
        "    logreg.fit(X_train_sel, y_train)\n",
        "    pred = logreg.predict(X_test_sel)\n",
        "    probs = logreg.predict_proba(X_test_sel)[:,1] if hasattr(logreg, 'predict_proba') else None\n",
        "    print(\"Logistic Regression test accuracy:\", accuracy_score(y_test, pred))\n",
        "    print(classification_report(y_test, pred))\n",
        "    if probs is not None:\n",
        "        try:\n",
        "            auc = roc_auc_score(y_test, probs)\n",
        "            print(\"ROC AUC:\", auc)\n",
        "            fpr, tpr, _ = roc_curve(y_test, probs)\n",
        "            plt.figure()\n",
        "            plt.plot(fpr, tpr)\n",
        "            plt.plot([0,1], [0,1], linestyle='--')\n",
        "            plt.title('ROC Curve (LogReg)')\n",
        "            plt.xlabel('False Positive Rate')\n",
        "            plt.ylabel('True Positive Rate')\n",
        "            roc_path = os.path.join(outdir, 'roc_curve.png')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(roc_path)\n",
        "            plt.close()\n",
        "            print(\"Saved ROC curve to\", roc_path)\n",
        "        except Exception as e:\n",
        "            print(\"Could not compute ROC AUC:\", e)\n",
        "\n",
        "    # 5) Save processed dataset & artifacts\n",
        "    # Build final feature names for the full preprocessor transform\n",
        "    X_all_prep = preprocessor.transform(X)\n",
        "    try:\n",
        "        final_feature_names = numeric_cols + list(preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(cat_cols))\n",
        "    except Exception:\n",
        "        final_feature_names = [f\"f{i}\" for i in range(X_all_prep.shape[1])]\n",
        "    processed_csv = os.path.join(outdir, 'processed_features.csv')\n",
        "    pd.DataFrame(X_all_prep, columns=final_feature_names).to_csv(processed_csv, index=False)\n",
        "    print(\"Saved processed features to\", processed_csv)\n",
        "\n",
        "    # Save artifacts\n",
        "    joblib.dump(preprocessor, os.path.join(outdir, 'preprocessor.joblib'))\n",
        "    joblib.dump(selector, os.path.join(outdir, 'selector.joblib'))\n",
        "    joblib.dump(logreg, os.path.join(outdir, 'model.joblib'))\n",
        "    print(\"Saved artifacts to\", outdir)\n",
        "\n",
        "    # Report selected features\n",
        "    try:\n",
        "        mask = selector.get_support()\n",
        "        selected_feats = [fn for fn, m in zip(final_feature_names, mask) if m]\n",
        "        print(\"Selected features after thresholding:\", selected_feats)\n",
        "    except Exception:\n",
        "        print(\"Could not list selected features.\")\n",
        "\n",
        "    print(\"\\nDone. See outputs in:\", outdir)\n",
        "\n",
        "# Define a simple object to mimic the argparse Namespace\n",
        "class Args:\n",
        "    def __init__(self, input=None, target=None, outdir='./output'):\n",
        "        self.input = input\n",
        "        self.target = target\n",
        "        self.outdir = outdir\n",
        "\n",
        "# Create an instance of Args and call main\n",
        "# To use synthetic data:\n",
        "main(Args())\n",
        "\n",
        "# To use your own CSV, uncomment the following line and replace the placeholders:\n",
        "# main(Args(input='path/to/your.csv', target='target_column_name', outdir='./output'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kd5FhpQsYjI",
        "outputId": "8619d117-8237-464f-e1f3-10bf88e80acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/smart_data_analyzer/smart_data_analyzer.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python smart_data_analyzer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrxfrttosiFz",
        "outputId": "75ff83c5-656e-4403-829b-d80a5da98e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/smart_data_analyzer/smart_data_analyzer.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python smart_data_analyzer.py --input path/to/your_file.csv --target your_target_column --outdir ./my_analysis"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
